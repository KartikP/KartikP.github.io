<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="">
<!-- Avoid warning on Google Chrome
        Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'.
        see https://stackoverflow.com/a/75119417
    -->
    <meta http-equiv="Permissions-Policy" content="interest-cohort=()">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>NDD-ePhys-dB development pipeline | Kartik  Pradeepan</title>
    <meta name="author" content="Kartik  Pradeepan">
    <meta name="description" content="How to create your own Allen Institute-style open access database">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
    <!-- <link rel="stylesheet" href="/assets/css/mdb.min.css?62a43d1430ddb46fc4886f9d0e3b49b8"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="http://localhost:4000/projects/Neurocyte%20Database%20Pipeline/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Kartik </span>Pradeepan</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">posts</a>
              </li>
              <!-- Notebook -->
              <li class="nav-item"><a class="nav-link" href="https://kartikp.github.io/Notebook" rel="external nofollow noopener" target="_blank">notebook</a></li> 
             <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
<!-- CV/Resume -->
               <li class="nav-item"><a class="nav-link" href="../assets/pdf/Kartik_Pradeepan_CV.pdf">cv</a></li>
               <li class="nav-item"><a class="nav-link" href="../assets/pdf/Kartik_Pradeepan_Resume.pdf">resume</a></li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fa-solid fa-moon"></i>
                  <i class="fa-solid fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
<div class="post">

  <header class="post-header">
    <h1 class="post-title">NDD-ePhys-dB development pipeline</h1>
    <p class="post-description">How to create your own Allen Institute-style open access database</p>
  </header>

  <article>
    <p>Over the next couple of months, I’ll be working on a <em>greenfield</em> data project. This kind of project is built from scratch, from the ground up, without any constraints from prior work. Here, I will provide the motivation and a high-level overview of how this project will be accomplished.</p>

<p>In neuroscience, there’s a growing trend of producing large datasets. Up to now, the focus has primarily been on transcriptomics, which has flourished thanks to high-throughput transcriptomic assays. Transcriptomics, a study of RNA transcripts, reveals gene expression profiles in neurons, offering insights into their potential functions and states. However, it represents just one aspect of neurobiology.</p>

<p>Another crucial, yet complex, type of data comes from electrophysiology — the study of electrical properties in cells. While it often centers on neurons, other cell types in the brain also exhibit interesting electrophysiological characteristics worth exploring. Electrophysiology is vital for understanding how neurons function: it looks at how they communicate, process information, and contribute to complex behaviors and brain activities. Unlike transcriptomics, which provides a static, broader view of what neurons might be capable of, electrophysiology offers a dynamic, real-time look at how neurons actually behave and interact.</p>

<p>The two primary tools used in electrophysiological research are patch-clamp and microelectrode arrays, each complementing the other in their application. Patch-clamp involves attaching a single electrode directly inside a cell and then applying current to see how the neuron reacts to these external stimuli. This technique has various forms and can be manipulated in different ways to explore distinct mechanisms and states of neurons.</p>

<p>In contrast, microelectrode arrays focus on the population-level activity of neuronal networks. This approach uses up to several thousand electrodes to record the activity of a group of neurons simultaneously, helping researchers understand how neurons interact within a network. Unlike the patch-clamp method, which ultimately kill the cell, microelectrode arrays are non-destructive. This non-destructive nature allows for the long-term observation of the same group of neurons, which is particularly valuable for studying their development over time. Due to this advantage, microelectrode arrays have become increasingly favored by scientists researching neurodevelopmental disorders.</p>

<p>The following project aims to facilitate data sharing and collaboration among various university/research labs investigating the electrophysiological properties of various neurodevelopmental disorders. The project was inspired by the Allen Institute for Brain Science Atlas, which provides the world’s most comprehensive collection of electrophysiology-transcriptomic-morphology recordings/reconstructions of rodent, non-human primate, and human neurons.</p>

<h1 id="the-data">The data</h1>

<p>Patch-clamp single neuron recordings are fairly straightforward. They are either in .abf or .nwb file formats and are generally only a few megabytes per experiment (containing various stimulation protocols, and the resulting output from the neuron). My current average file size here is approximately 1.3 megabytes. If I have 1000 neurons, the total file size will be 1300 megabytes. Not much at all.</p>

<p>Microelectrode array recordings are considerably more complex. These recordings vary based on the number of recording electrodes and the sampling frequency. For example, Axion Biosystem’s Maestro MEA contains 12 wells, each containing 64 channels. It records at a sampling frequency of 12.5 kHz, meaning every second, there are 12500 data points per channel. Every second, across the entire plate (which contains 12 wells x 64 channels), there are 9,600,000 data points. Each data point, if I recall correctly, is 2-bytes. Therefore, each second, this produces 19,200,000 bytes of data or 18.3105 MB. A 5 minute recording (300 seconds), will produce a file size of 5.49315 GB. If you record multiple time points over 6 weeks (lets say twice a week), the total dataset size for one plate is approximately 65.9 GB. If you do this 10 times (as biological replicates), the full dataset will be 659 GB. This is considerably larger than the patch-clamp data.</p>

<h1 id="the-pipeline">The pipeline</h1>
<p>I want to build a pipeline that will accept both of these file types in their raw format (extract), process the data (transform), and then store the harmonized data into various tables (load). I decided to go completely with Amazon Web Services (AWS) for this.</p>

<p><img width="100%" alt="image" src="../../assets/img/Neurocyte%20Data%20Pipeline/Neurocyte%20Data%20Pipeline.png"></p>

<h3 id="data-ingestion-and-initial-storage">Data Ingestion and Initial Storage</h3>

<ol>
  <li>
<strong>Data Sources to AWS S3 via AWS Direct Connect and Internet</strong>:
    <ul>
      <li>Internal data sources are transferred to AWS S3 using AWS Direct Connect. This dedicated network connection ensures a more reliable and consistent network experience compared to standard internet-based connections.</li>
      <li>External data sources upload data directly onto S3 via the internet. This setup provides a straightforward and accessible method for external data ingestion.</li>
    </ul>
  </li>
</ol>

<h3 id="data-processing">Data Processing</h3>

<ol>
  <li>
<strong>Data Processing with AWS Glue and Spark</strong>:
    <ul>
      <li>Once in S3, the data triggers AWS Glue jobs. AWS Glue, a serverless data integration service, is configured to run Spark operations on this data.</li>
      <li>Spark operations in Glue are used to transform and process the raw data. This step will clean, aggregate, and process the data.</li>
    </ul>
  </li>
</ol>

<h3 id="processed-data-storage">Processed Data Storage</h3>

<ol>
  <li>
<strong>Storing Processed Data on S3</strong>:
    <ul>
      <li>After processing, the transformed data is stored back in AWS S3. This separation of raw and processed data helps maintain an organized and efficient data storage strategy.</li>
    </ul>
  </li>
</ol>

<h3 id="data-cataloging-and-querying">Data Cataloging and Querying</h3>

<ol>
  <li>
<strong>Cataloging Data with Glue Crawlers</strong>:
    <ul>
      <li>AWS Glue Crawlers are then used to scan the processed data stored in S3. These crawlers automatically catalog the data, making it searchable and queryable. They classify the data and extract schema and metadata, which are then stored in the AWS Glue Data Catalog.</li>
    </ul>
  </li>
  <li>
<strong>Querying Data with Athena</strong>:
    <ul>
      <li>The cataloged data is queried using AWS Athena, an interactive query service. Athena allows SQL queries directly on data stored in S3, providing a flexible and powerful way to analyze large datasets without the need for traditional database servers. Compared to RedShift, Athena charges per query versus the total runtime. For my purpose, this is currently advisable however may change on usage.</li>
    </ul>
  </li>
</ol>

<h3 id="api-integration-and-data-retrieval">API Integration and Data Retrieval</h3>

<ol>
  <li>
<strong>API Gateway and Lambda for Data Retrieval</strong>:
    <ul>
      <li>An AWS API Gateway is set up to manage and route requests. This acts as a front door to your data processing backend.</li>
      <li>AWS Lambda functions are triggered by this API Gateway to handle specific tasks such as querying Athena for data visualization or directly retrieving files from S3 for user download.</li>
      <li>This setup ensures that data retrieval and processing are efficiently managed, scalable, and secure.</li>
    </ul>
  </li>
</ol>

<h3 id="frontend-visualization-and-download-not-shown">Frontend Visualization and Download (not shown)</h3>

<ol>
  <li>
<strong>Frontend Data Visualization and Download</strong>:
    <ul>
      <li>On the frontend, user requests to view or download data are handled through interactions with the website.</li>
      <li>For data visualization, Plotly, a powerful graphing library, is used. It renders interactive visualizations in the user’s browser based on the JSON-generated data retrieved through the API Gateway and Lambda functions.</li>
      <li>For data downloads, the Lambda function fetches the requested files directly from S3 and facilitates the download process for the user.</li>
    </ul>
  </li>
</ol>

<h1 id="estimated-cost">Estimated Cost</h1>
<p>Now it’s great to design a full-fledged pipeline and while it’s most likely functional and get the job done, it’s really important to consider the the costs of all the products that I will be using. To do this, I will provide a hypothetical but realistic scenario.</p>

<h2 id="description-of-files">Description of Files</h2>

<p>Microelectrode array: 20 plates, with 12 time points. Axion Biosystems RAW file format. 5.5GB per file. Total size is 1320GB.</p>
<ul>
  <li>CSV pre-processed: 20 plates, with 12 time points. Comma separated value file format. 300MB per 12 time points. Total size is 6GB.</li>
</ul>

<p>Patch clamp: 100 recordings. ABF file format. 1.3MB per file. Total size is  1.3GB.</p>

<p>Total size of all raw files: 1327.3GB rounded up to 1328GB</p>

<h2 id="storage-pricing">Storage Pricing</h2>
<p>Amazon S3 Pricing: https://aws.amazon.com/s3/pricing/</p>

<h3 id="transfer-in">Transfer In</h3>
<p>Transferring in is $0.00 per GB</p>

<h3 id="storage">Storage</h3>
<p>S3 Intelligent - Tiering - General purpose storage for any type of data, typically used for frequently accessed data.</p>

<p>Frequent Access Tier, First 50TB/Month: $0.023 per GB
Total for <strong>just</strong> storage: $30.544</p>

<h3 id="requests">Requests</h3>
<p>As shown in the pipeline, once the initial data is stored on S3, AWS Glue via PySpark will retrieve the data to perform a variety of transformations and processing.</p>

<p>Theoretically, each file should be only requested once by AWS Glue.</p>

<p>The total number of GET requests will be approximately 580 (for the total number of files). GET/SELECT requests are $0.0004 per 1000 requests. Therefore, this one time cost during initialization will be $0.0004.</p>

  </article>
</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Kartik  Pradeepan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.
Last updated: January 15, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="/assets/js/bootstrap.bundle.min.js"></script>
  <!-- <script src="/assets/js/mdb.min.js"></script> -->
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-M1JHV55BQ5"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-M1JHV55BQ5');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
